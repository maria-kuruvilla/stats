<<<<<<< HEAD
r <- pars[1]
N1978 <- pars[2]
sigma <- pars[3]
ndata <- length(Ntobs)
Nt <- rep(NA, ndata)
epsilon_t <- rep(NA, ndata)
Nt[1] <- N1978
### write code to estimate Nt for all years
### then calculate epsilon_t
### then caclulate the sum of the negative log likelihood, removing NA's:
# e.g.: - sum(dnorm(x = epsilon_t, mean = 0, sd = sigma, log = T), na.rm = TRUE)
### make sure the function returns the sum of negative log likelihoods
for(i in 1:(ndata-1)){
Nt[i+1] <- Nt[i] + r* Nt[i]
}
epsilon_t <- Ntobs - Nt
#return(Nt)
#return(epsilon_t)
return( - sum(dnorm(x = epsilon_t, mean = 0, sd = sigma, log = T), na.rm = TRUE))
}
start.pars <- c(0.1, 3000, 400) # these seem to "work"
ddind.soln <- optim(start.pars, density.independent.nll, method = "BFGS", Ntobs = Ntobs)
ddind.soln
# a function for caclulating negative log likelihood for density independent model
density.independent.nll <- function(pars, Ntobs) {
r <- pars[1]
N1978 <- pars[2]
sigma <- pars[3]
ndata <- length(Ntobs)
Nt <- rep(NA, ndata)
epsilon_t <- rep(NA, ndata)
Nt[1] <- N1978
### write code to estimate Nt for all years
### then calculate epsilon_t
### then caclulate the sum of the negative log likelihood, removing NA's:
# e.g.: - sum(dnorm(x = epsilon_t, mean = 0, sd = sigma, log = T), na.rm = TRUE)
### make sure the function returns the sum of negative log likelihoods
for(i in 1:(ndata-1)){
Nt[i+1] <- Nt[i] + r* Nt[i]
}
epsilon_t <- Ntobs - Nt
return(Nt)
return(epsilon_t)
return( - sum(dnorm(x = epsilon_t, mean = 0, sd = sigma, log = T), na.rm = TRUE))
}
density.independent.nll(start.pars,Ntobs)
density.independent.nll <- function(pars, Ntobs) {
r <- pars[1]
N1978 <- pars[2]
sigma <- pars[3]
ndata <- length(Ntobs)
Nt <- rep(NA, ndata)
epsilon_t <- rep(NA, ndata)
Nt[1] <- N1978
### write code to estimate Nt for all years
### then calculate epsilon_t
### then caclulate the sum of the negative log likelihood, removing NA's:
# e.g.: - sum(dnorm(x = epsilon_t, mean = 0, sd = sigma, log = T), na.rm = TRUE)
### make sure the function returns the sum of negative log likelihoods
for(i in 1:(ndata-1)){
Nt[i+1] <- Nt[i] + r* Nt[i]
}
epsilon_t <- Ntobs - Nt
print(Nt)
print(epsilon_t)
return( - sum(dnorm(x = epsilon_t, mean = 0, sd = sigma, log = T), na.rm = TRUE))
}
density.independent.nll(start.pars,Ntobs)
mean(epsilon_t)
# a function for caclulating negative log likelihood for density independent model
density.independent.nll <- function(pars, Ntobs) {
r <- pars[1]
N1978 <- pars[2]
sigma <- pars[3]
ndata <- length(Ntobs)
Nt <- rep(NA, ndata)
epsilon_t <- rep(NA, ndata)
Nt[1] <- N1978
### write code to estimate Nt for all years
### then calculate epsilon_t
### then caclulate the sum of the negative log likelihood, removing NA's:
# e.g.: - sum(dnorm(x = epsilon_t, mean = 0, sd = sigma, log = T), na.rm = TRUE)
### make sure the function returns the sum of negative log likelihoods
for(i in 1:(ndata-1)){
Nt[i+1] <- Nt[i] + r* Nt[i]
}
epsilon_t <- Ntobs - Nt
print(Nt)
print(mean(epsilon_t))
return( - sum(dnorm(x = epsilon_t, mean = 0, sd = sigma, log = T), na.rm = TRUE))
}
start.pars <- c(0.1, 3000, 400) # these seem to "work"
ddind.soln <- optim(start.pars, density.independent.nll, method = "BFGS", Ntobs = Ntobs)
ddind.soln
Nt[1] <- N1978
N1978 <- pars[2]
start.pars <- c(0.1, 3000, 400)
N1978 <- start.pars[2]
for(i in 1:(ndata-1)){
Nt[i+1] <- Nt[i] + r* Nt[i]
}
ndata <- length(Ntobs)
Nt <- rep(NA, ndata)
epsilon_t <- rep(NA, ndata)
Nt[1] <- N1978
for(i in 1:(ndata-1)){
Nt[i+1] <- Nt[i] + r* Nt[i]
}
r <- start.pars[1]
for(i in 1:(ndata-1)){
Nt[i+1] <- Nt[i] + r* Nt[i]
}
Nt
epsilon_t <- Ntobs - Nt
epsilon_t
install.packages("xtable")
library(readr)
stats_speed <- read_csv("Documents/data/temp_collective/roi/stats_speed.csv")
View(stats_speed)
speed <- stats_speed$`90_speed`
temp <- stats_speed$Temperature
gs <- stats_speed$Groupsize
n <- length(stats_speed$`90_speed`)
speed_data <- as.data.frame(cbind(sample = (1:n),speed,temp,gs))
model <- lm(speed ~ temp + gs,speed_data)
model$coefficients
plot(fitted(model),model$residuals)
plot(fitted(model),sqrt(abs(model$residuals)))
=======
model1 <- lm(Vel ~ Wt ,HW5marmot_speed)
#2a
#Show, for your most complex model, the R code to calculate AIC, AICc, and BIC
#based on the residual sum of squares, n, and K for the model.
p_full_model <- nrow(summary(full_model)$coefficients)
RSS_full <- anova(full_model)$'Sum Sq'[ nrow(anova(full_model))]
#AIC
aic_full <- n*log(RSS_full/n) + p_full_model*2
#AICC
aicc_full <- extractAIC(full_model)[2] + ((2*p_full_model*(p_full_model+1)) /(n - p_full_model - 1))
#BIC
bic_full <- n*log(RSS_full/n) + p_full_model*log(n)
#b. Produce and report a table including the sigma hat squared, the number of parameters, the AIC,
#the AICc, and the BIC for each of your candidate models.
p <- RSS <- aic <- aicc <- bic <- rep(NA,8)
p[1] <- nrow(summary(model1)$coefficients)
p[2] <- nrow(summary(model2)$coefficients)
p[3] <- nrow(summary(model3)$coefficients)
p[4] <- nrow(summary(model4)$coefficients)
p[5] <- nrow(summary(model5)$coefficients)
p[6] <- nrow(summary(model6)$coefficients)
p[7] <- nrow(summary(model7)$coefficients)
p[8] <- p_full_model
RSS[1] <- anova(model1)$'Sum Sq'[ nrow(anova(model1))]
RSS[2] <- anova(model2)$'Sum Sq'[ nrow(anova(model2))]
RSS[3] <- anova(model3)$'Sum Sq'[ nrow(anova(model3))]
RSS[4] <- anova(model4)$'Sum Sq'[ nrow(anova(model4))]
RSS[5] <- anova(model5)$'Sum Sq'[ nrow(anova(model5))]
RSS[6] <- anova(model6)$'Sum Sq'[ nrow(anova(model6))]
RSS[7] <- anova(model7)$'Sum Sq'[ nrow(anova(model7))]
RSS[8] <- RSS_full
aic[1] <- n*log(RSS[1]/n) + p[1]*2
aic[2] <- n*log(RSS[2]/n) + p[2]*2
aic[3] <- n*log(RSS[3]/n) + p[3]*2
aic[4] <- n*log(RSS[4]/n) + p[4]*2
aic[5] <- n*log(RSS[5]/n) + p[5]*2
aic[6] <- n*log(RSS[6]/n) + p[6]*2
aic[7] <- n*log(RSS[7]/n) + p[7]*2
aic[8] <- aic_full
#AICC
aicc[1] <- extractAIC(model1)[2] + ((2*p[1]*(p[1]+1)) /(n - p[1] - 1))
aicc[2] <- extractAIC(model2)[2] + ((2*p[2]*(p[2]+1)) /(n - p[2] - 1))
aicc[3] <- extractAIC(model3)[2] + ((2*p[3]*(p[3]+1)) /(n - p[3] - 1))
aicc[4] <- extractAIC(model4)[2] + ((2*p[4]*(p[4]+1)) /(n - p[4] - 1))
aicc[5] <- extractAIC(model5)[2] + ((2*p[5]*(p[5]+1)) /(n - p[5] - 1))
aicc[6] <- extractAIC(model6)[2] + ((2*p[6]*(p[6]+1)) /(n - p[6] - 1))
aicc[7] <- extractAIC(model7)[2] + ((2*p[7]*(p[7]+1)) /(n - p[7] - 1))
aicc[8] <- aicc_full
#BIC
bic[1] <- n*log(RSS[1]/n) + p[1]*log(n)
bic[2] <- n*log(RSS[2]/n) + p[2]*log(n)
bic[3] <- n*log(RSS[3]/n) + p[3]*log(n)
bic[4] <- n*log(RSS[4]/n) + p[4]*log(n)
bic[5] <- n*log(RSS[5]/n) + p[5]*log(n)
bic[6] <- n*log(RSS[6]/n) + p[6]*log(n)
bic[7] <- n*log(RSS[7]/n) + p[7]*log(n)
bic[8] <- bic_full
aic
bic
aicc
table <- as.data.frame(cbind(RSS,p,aic,aicc,bic))
table
xtable(table)
install.packages("boot")
install.packages("boot")
model7 <- lm(Vel ~ as.factor(Sex)+as.factor(Sub)+Wt ,HW5marmot_speed, x= TRUE, y= TRUE)
model6 <- lm(Vel ~ as.factor(Sub)+Slpe+Wt ,HW5marmot_speed, x= TRUE, y= TRUE)
model5 <- lm(Vel ~ as.factor(Sex)+Slpe+Wt ,HW5marmot_speed, x= TRUE, y= TRUE)
model4 <- lm(Vel ~ as.factor(Sub)+Wt ,HW5marmot_speed, x= TRUE, y= TRUE)
model3 <- lm(Vel ~ as.factor(Sex)+Wt ,HW5marmot_speed, x= TRUE, y= TRUE)
model2 <- lm(Vel ~ Slpe+Wt ,HW5marmot_speed, x= TRUE, y= TRUE)
model1 <- lm(Vel ~ Wt ,HW5marmot_speed, x= TRUE, y= TRUE)
loo <- rep(NA,8)
require(boot)
loo[1] <- cv.glm(data = HW5marmot_speed, model1, K=n)$delta[1]
loo[2] <- cv.glm(data = HW5marmot_speed, model2, K=n)$delta[1]
loo[3] <- cv.glm(data = HW5marmot_speed, model3, K=n)$delta[1]
loo[4] <- cv.glm(data = HW5marmot_speed, model4, K=n)$delta[1]
loo[5] <- cv.glm(data = HW5marmot_speed, model5, K=n)$delta[1]
loo[6] <- cv.glm(data = HW5marmot_speed, model6, K=n)$delta[1]
loo[7] <- cv.glm(data = HW5marmot_speed, model7, K=n)$delta[1]
loo[8] <- cv.glm(data = HW5marmot_speed, full_model, K=n)$delta[1]
loo
full_model <- lm(Vel ~ as.factor(Sex)+as.factor(Sub)+Slpe+Wt ,HW5marmot_speed, x= TRUE, y=TRUE)
loo[8] <- cv.glm(data = HW5marmot_speed, full_model, K=n)$delta[1]
loo
install.packages("rmarkdown")
install.packages("rnaturalearth")
install.packages("gifski")
install.packages("transformr")
devtools::install_github("thomasp85/transformr")
devtools::install_github("thomasp85/transformr")
install.packages("tidyverse")
install.packages("lubridate")
install.packages("lubridate")
install.packages("sf")
install.packages("ggplot2")
install.packages("mapview")
install.packages("adehabitatLT")
install.packages("move")
install.packages("raster")
install.packages("knitr")
install.packages("devtools")
install.packages("moveHMM")
install.packages("bcpa")
devtools:: install_github("thomasp85/gganimate")
devtools:: install_github("thomasp85/gganimate")
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
knitr::opts_knit$set(root.dir = '~/Dropbox/Research/R Tutorial Scripts & Workshops/Abrahms UW Movement Analysis Workshop/Workshop Materials/')
library(gganimate)
devtools::install_github("thomasp85/transformr")
devtools::install_github("ropensci/rerddap")
a <- 2
b <- 3
source('~/QERM/2020/QSCI 454/Week 1/Lab/labR.R')
a <- 2
b <- 3
a+b
seq(a,b)
seq(1,5)
rep(0,5)
N_0 <- seq(0,20)
x <- rep(na,21)
x <- rep("na",21)
x <- rep(NA,21)
output <- rep(NA,length(years))
years <- seq(0,tmax)
output <- rep(NA,length(years))
r <- 0.2
K <- 100
N_0 <- 10
tmax <- 20
years <- seq(0,tmax)
output <- rep(NA,length(years))
output[1] <- N_0
for(i in years){
output[i+1]=output[i] + output[i]*r*(1-output[i]/K)
}
for(i in years){
output[i+1] <- output[i] + output[i]*r*(1-output[i]/K)
}
for(i in 1:tmax){
output[i+1] <- output[i] + output[i]*r*(1-output[i]/K)
}
plot(years, output)
install.packages('manipulate')
source('~/QERM/2020/QSCI 454/Week 2/LogisticRStudio.R')
source('~/QERM/2020/QSCI 454/Week 2/LogisticRStudio.R')
source('~/QERM/2020/QSCI 454/Week 2/LogisticRStudio.R')
F3 <- 10
F4 <- 15
F5 <- 20
S1 <- 0.2
S2 <- 0.3
S3 <- 0.4
S4 <- 0.5
# Initial Conditions
N1.0 <- 20
N2.0 <- 15
N3.0 <- 10
N4.0 <- 5
N5.0 <- 1
N <- matrix (NA, nrow = 100, ncol = 5)
colnames(N)<- c("Age 1", "Age 2", "Age 3", "Age 4", "Age 5")
N[1,]<- c(N1.0, N2.0, N3.0, N4.0, N5.0)
for (i in 2:100){
N[i,1]<-  F3*N[i-1,3] + F4*N[i-1,4] + F5*N[i-1,5]
N[i,2]<- S1*N[i-1,1]
N[i,3]<- S2*N[i-1,2]
N[i,4]<- S3*N[i-1,3]
N[i,5]<- S4*N[i-1,4]
}
N.stable <- N[100,]
lambda <- sum(N[100,])
lambda <- sum(N[100,])/sum(N[99,])
prop1 <- N[100,1]/sum(N[100,])
prop2 <- N[100,2]/sum(N[100,])
prop3 <- N[100,3]/sum(N[100,])
prop4 <- N[100,4]/sum(N[100,])
prop5 <- N[100,5]/sum(N[100,])
print(lambda)
# plot the output
par(las =1)
color.list <- c("black","purple", "blue","grey","red")
plot(1:100, N[,1],
type = "l",
lwd = 2,
xaxs = "i",
yaxs = "i",
ylab = "Abundance",
xlab = "Year",
col = "black")
for (i in 1:4) lines(1:100, N[,i], lwd = 2, col = color.list[i])
#reduce f3
F3 <- F3/2
for (i in 2:100){
N[i,1]<-  F3*N[i-1,3] + F4*N[i-1,4] + F5*N[i-1,5]
N[i,2]<- S1*N[i-1,1]
N[i,3]<- S2*N[i-1,2]
N[i,4]<- S3*N[i-1,3]
N[i,5]<- S4*N[i-1,4]
}
lambda <- sum(N[100,])/sum(N[99,])
print(lambda)
F3 <- F3*2
F4 <- F4/2
for (i in 2:100){
N[i,1]<-  F3*N[i-1,3] + F4*N[i-1,4] + F5*N[i-1,5]
N[i,2]<- S1*N[i-1,1]
N[i,3]<- S2*N[i-1,2]
N[i,4]<- S3*N[i-1,3]
N[i,5]<- S4*N[i-1,4]
}
lambda <- sum(N[100,])/sum(N[99,])
print(lambda)
F4 <- F4*2
F5 <- F5/2
for (i in 2:100){
N[i,1]<-  F3*N[i-1,3] + F4*N[i-1,4] + F5*N[i-1,5]
N[i,2]<- S1*N[i-1,1]
N[i,3]<- S2*N[i-1,2]
N[i,4]<- S3*N[i-1,3]
N[i,5]<- S4*N[i-1,4]
}
lambda <- sum(N[100,])/sum(N[99,])
print(lambda)
F5 <- F5*2
#reduce s1
S1 <- S1/2
for (i in 2:100){
N[i,1]<-  F3*N[i-1,3] + F4*N[i-1,4] + F5*N[i-1,5]
N[i,2]<- S1*N[i-1,1]
N[i,3]<- S2*N[i-1,2]
N[i,4]<- S3*N[i-1,3]
N[i,5]<- S4*N[i-1,4]
}
lambda <- sum(N[100,])/sum(N[99,])
print(lambda)
S1 <- S1*2
S2 <- S2/2
for (i in 2:100){
N[i,1]<-  F3*N[i-1,3] + F4*N[i-1,4] + F5*N[i-1,5]
N[i,2]<- S1*N[i-1,1]
N[i,3]<- S2*N[i-1,2]
N[i,4]<- S3*N[i-1,3]
N[i,5]<- S4*N[i-1,4]
}
lambda <- sum(N[100,])/sum(N[99,])
print(lambda)
S2 <- S2*2
S3 <- S3/2
for (i in 2:100){
N[i,1]<-  F3*N[i-1,3] + F4*N[i-1,4] + F5*N[i-1,5]
N[i,2]<- S1*N[i-1,1]
N[i,3]<- S2*N[i-1,2]
N[i,4]<- S3*N[i-1,3]
N[i,5]<- S4*N[i-1,4]
}
lambda <- sum(N[100,])/sum(N[99,])
print(lambda)
S3 <- S1*3
S4 <- S4/2
for (i in 2:100){
N[i,1]<-  F3*N[i-1,3] + F4*N[i-1,4] + F5*N[i-1,5]
N[i,2]<- S1*N[i-1,1]
N[i,3]<- S2*N[i-1,2]
N[i,4]<- S3*N[i-1,3]
N[i,5]<- S4*N[i-1,4]
}
lambda <- sum(N[100,])/sum(N[99,])
print(lambda)
S4 <- S4*2
source('~/QERM/2020/QSCI 454/Week 3/treesnake_MonteCarlo.R')
output[1]
source('~/QERM/2020/QSCI 454/Week 3/treesnake_ipp.R')
## ============================================================================
## FISH 454 Ecological Modeling - Winter 2014
## Lab #3 - Monte Carlo simulations
## January 2020
## ============================================================================
rm(list = ls()) # wipes all variables from the memory.  good for debugging.
source('~/QERM/2020/QSCI 454/Week 3/treesnake_MonteCarlo.R')
runMC
runMC(,1)
runMC[,1]
max(runMC[,1])
setwd("~/Documents/code/stats")
data <- read.csv("../../data/temp_collective/roi/stats_loom_latency_nan.csv",header=TRUE,na.strings=c("[nan]"))
getwd()
setwd("C:/Users/Maria Kuruvilla/Documents/code/stats")
data <- read.csv("../../data/temp_collective/roi/stats_loom_latency_nan.csv",header=TRUE,na.strings=c("[nan]"))
stats_speed <- read.csv("../../data/temp_collective/roi/stats_speed.csv",header=TRUE,na.strings=c("[nan]"))
View(stats_speed)
speed <- stats_speed$X90_speed
temp <- stats_speed$Temperature
gs <- stats_speed$Groupsize
n <- length(stats_speed$X90_speed)
speed_data <- as.data.frame(cbind(sample = (1:n),speed,temp,gs))
model <- lm(speed ~ temp + gs,speed_data)
summary(model)
plot(fitted(model), residuals(model))
>>>>>>> 2d075bd6684d6849204457f05e6bb5e0a9ad2f87
qqnorm(residuals(model))
qqline(residuals(model))
plot.default(temp,model$residuals)
plot.default(gs,model$residuals)
plot.default(temp,model$residuals)
plot(fitted(model),model$residuals)
shapiro.test(residuals(model))
install.packages(c("faraway", "lessR"))
summary(model)
boxcox(model, plotit = TRUE)
install.packages("EnvStats")
boxcox(model, plotit = TRUE)
require(EnvStats)
boxcox(model, plotit = TRUE)
boxcox(model, plotit = TRUE)
install.packages("MASS")
require(MASS)
boxcox(model, plotit = TRUE)
boxcox(model, plotit = FALSE)
10^(0.1)
model_transform <- lm(speed^0.1 ~ temp + gs,speed_data)
summary(model_transform)
plot(fitted(model_transform), residuals(model_transform))
qqnorm(residuals(model_transform))
qqline(residuals(model_transform))
ln(1)
log(1)
log(10)
log(2.7)
model_exp <- lm(log(speed) ~ temp + gs,speed_data)
summary(model_exp)
plot(fitted(model_exp), residuals(model_exp))
qqnorm(residuals(model_exp))
qqline(residuals(model_exp))
plot(fitted(model_exp), residuals(model_exp))
plot(fitted(model), residuals(model))
shapiro.test(residuals(model_exp))
<<<<<<< HEAD
exp(2)
transform.bc <- function(x)(exp(x))
data.frame(x = temp)
data.frame(x = temp + gs)
summary(model_exp)
transform.bc <- function(x)(exp(x))
out <- predict(lmod.t, newdata = data.frame(x = temp), interval="prediction")
transform.bc <- function(x)(exp(x))
out <- predict(model_exp, newdata = data.frame(x = temp), interval="prediction")
plot(speed ~ temp, ylab = "90th percentile of speed", xlab = "Temperature")
lines(sort(temp),sort(transform.bc(out)[,1] ) ,col="red")
lines(sort(temp),sort(transform.bc(out)[,2] ),lty = 2,col="red")
plot(speed ~ temp, ylab = "90th percentile of speed", xlab = "Temperature")
lines(sort(temp),sort(transform.bc(out)[,1] ) ,col="red")
lines(sort(temp),sort(transform.bc(out)[,2] ),lty = 2,col="red")
lines(sort(temp),sort(transform.bc(out)[,3] ),lty = 2,col="red")
seq(9, 29, by=2)
data.frame(x = seq(9,29,by = 2))
transform.bc <- function(x)(exp(x))
out <- predict(model_exp, newdata = data.frame(x =seq(9,29,by = 2)), interval="prediction")
plot(speed ~ temp, ylab = "90th percentile of speed", xlab = "Temperature")
lines(sort(temp),sort(transform.bc(out)[,1] ) ,col="red")
lines(sort(temp),sort(transform.bc(out)[,2] ),lty = 2,col="red")
lines(sort(temp),sort(transform.bc(out)[,3] ),lty = 2,col="red")
lines(seq(9,29,by = 2),sort(transform.bc(out)[,1] ) ,col="red")
lines(seq(9,29,by = 2),sort(transform.bc(out)[,2] ),lty = 2,col="red")
lines(seq(9,29,by = 2),sort(transform.bc(out)[,3] ),lty = 2,col="red")
sort(transform.bc(out)[,1]
a
transform.bc(out)
out <- predict(model_exp, newdata = data.frame(x =seq(9,29,by = 2)), interval="prediction")
transform.bc(out)
out2 <- predict(model_exp, newdata = data.frame(x = gs), interval="prediction")
plot(speed ~ gs, ylab = "90th percentile of speed", xlab = "Group Size")
lines(sort(gs),sort(transform.bc(out2)[,1] ) ,col="red")
lines(sort(gs),sort(transform.bc(out2)[,2] ),lty = 2,col="red")
lines(sort(gs),sort(transform.bc(out2)[,3] ),lty = 2,col="red")
Correlation(temp,gs)
install.packages("lessR")
require(lessR)
install.packages("latticeExtra"")
a
adf
f
s
vswrdvw
dsvsvs
speeed
speed
h <- hatvalues(model_exp)
two_p_over_n <- 2*mean(h)
speed_data$sample[which(h>two_p_over_n)]
num <- speed_data$sample
halfnorm(h,nlab = 5, labs= num, ylab="Leverages")
require(faraway)
install.packages("faraway")
require(faraway)
install.packages("lme4")
library(readr)
stats_speed_acc_latency <- read_csv("Documents/data/temp_collective/roi/stats_speed_acc_latency.csv")
View(stats_speed_acc_latency)
library(readr)
stats_loom_latency <- read_csv("Documents/data/temp_collective/roi/stats_loom_latency.csv")
View(stats_loom_latency)
=======
model_exp_inv <- lm(log(speed) ~ temp*gs,speed_data)
summary(model_exp_inv)
plot(fitted(model_exp_inv), residuals(model_exp_inv))
qqnorm(residuals(model_exp_inv))
qqline(residuals(model_exp_inv))
shapiro.test(residuals(model_exp_inv))
stats_speed_acc_latency <- read.csv("../../data/temp_collective/roi/stats_speed_acc_latency.csv",header=TRUE,na.strings=c("[nan]"))
acc <- stats_speed_acc_latency$`90_acc`
lat <- stats_speed_acc_latency$latency
temp <- stats_speed_acc_latency$Temperature
gs <- stats_speed_acc_latency$Groupsize
n <- length(stats_speed_acc_latency$`90_acc`)
data <- as.data.frame(cbind(sample = (1:n),temp,gs,acc,lat))
model_acc <- lm(acc ~ temp + gs,data)
summary(model_acc)
View(stats_speed_acc_latency)
acc <- stats_speed_acc_latency$X90_acc
n <- length(stats_speed_acc_latency$`90_acc`)
data <- as.data.frame(cbind(sample = (1:n),temp,gs,acc,lat))
model_acc <- lm(acc ~ temp + gs,data)
summary(model_acc)
plot(fitted(model_acc), residuals(model_acc))
qqnorm(residuals(model_acc))
qqline(residuals(model_acc))
shapiro.test(residuals(model_acc))
data <- read.csv("../../data/temp_collective/roi/stats_loom_latency_nan.csv",header=TRUE,na.strings=c("[nan]"))
lat <- data$latency
#lat <- as.numeric(lat1)
temp <- data$Temperature
gs <- data$Groupsize
loom <- data$loom
n <- length(lat)
model1 <- lm(lat ~ temp + gs,data)
summary(model1)
model8 <- lm(lat ~ loom*gs + temp + I(temp^2),data)
summary(model8)
plot(fitted(model8), residuals(model8))
qqnorm(residuals(model8))
qqline(residuals(model8))
View(data)
model_pois <- glm(lat ~ temp + gs, family = poisson, data)
summary(model_pois)
model_pois2 <- glm(lat ~ temp*gs, family = poisson, data)
summary(model_pois2)
data <- read.csv("../../data/temp_collective/roi/startles_ratio_csv.csv",header=TRUE,na.strings=c("[nan]"))
accuracy <- data$accuracy
temp <- data$Temperature
gs <- data$Groupsize
date <- as.numeric(as.Date(data$Date, format = "%d/%m/%Y"))
time_in <- as.numeric(as.POSIXct(data$Time_fish_in, format = "%H:%M"))
time_record <- as.numeric(as.POSIXct(data$Time_start_record, format = "%H:%M"))
difference <- time_record - time_in
model1 <- lm(accuracy ~ temp + gs,data)
summary(model1)
plot(fitted(model1), residuals(model1))
qqnorm(residuals(model1))
qqline(residuals(model1))
View(data)
data1 <- read.csv("../../data/temp_collective/roi/startles_ratio_zero.csv",header=TRUE,na.strings=c("[nan]"))
accuracy1 <- data1$accuracy
temp1 <- data1$Temperature
gs1 <- data1$Groupsize
date1 <- as.numeric(as.Date(data1$Date, format = "%d/%m/%Y"))
time_in1 <- as.numeric(as.POSIXct(data1$Time_fish_in, format = "%H:%M"))
time_record1 <- as.numeric(as.POSIXct(data1$Time_start_record, format = "%H:%M"))
difference1 <- time_record - time_in
model4 <- lm(accuracy1 ~ temp1 + gs1,data1)
summary(model4)
plot(fitted(model4), residuals(model4))
qqnorm(residuals(model4))
qqline(residuals(model4))
require(MASS)
boxcox(model4,plotit=TRUE)
model5 <- lm(accuracy1^(3/2) ~ temp1 + gs1,data1)
summary(model5)
plot(fitted(model5), residuals(model5))
qqnorm(residuals(model5))
qqline(residuals(model5))
stats_speed <- read.csv("../../data/temp_collective/roi/stats_speed.csv",header=TRUE,na.strings=c("[nan]"))
speed <- stats_speed$X90_speed
temp <- stats_speed$Temperature
gs <- stats_speed$Groupsize
n <- length(stats_speed$X90_speed)
speed_data <- as.data.frame(cbind(sample = (1:n),speed,temp,gs))
model <- lm(speed ~ temp + gs,speed_data)
summary(model)
plot(fitted(model), residuals(model))
qqnorm(residuals(model))
qqline(residuals(model))
shapiro.test(residuals(model))
model_int <- lm(speed ~ temp*gs,speed_data)
summary(model_int)
plot(fitted(model_int), residuals(model_int))
qqnorm(residuals(model_int))
qqline(residuals(model_int))
require(MASS)
boxcox(model_int,plotit=TRUE)
model_exp <- lm(log(speed) ~ temp + gs,speed_data)
summary(model_exp)
plot(fitted(model_exp), residuals(model_exp))
qqnorm(residuals(model_exp))
qqline(residuals(model_exp))
shapiro.test(residuals(model_exp))
model_exp_inv <- lm(log(speed) ~ temp*gs,speed_data)
summary(model_exp_inv)
plot(fitted(model_exp_inv), residuals(model_exp_inv))
qqnorm(residuals(model_exp_inv))
qqline(residuals(model_exp_inv))
shapiro.test(residuals(model_exp_inv))
acc <- stats_speed_acc_latency$X90_acc
hist(acc)
>>>>>>> 2d075bd6684d6849204457f05e6bb5e0a9ad2f87
lat <- stats_speed_acc_latency$latency
temp <- stats_speed_acc_latency$Temperature
gs <- stats_speed_acc_latency$Groupsize
n <- length(stats_speed_acc_latency$latency)
data <- as.data.frame(cbind(sample = (1:n),temp,gs,acc,lat))
<<<<<<< HEAD
model_lat <- lm(lat ~ temp + gs,data)
summary(model_lat)
acc <- stats_speed_acc_latency$`90_acc`
data <- as.data.frame(cbind(sample = (1:n),temp,gs,acc,lat))
model_lat <- lm(lat ~ temp + gs,data)
summary(model_lat)
plot(fitted(model_lat), residuals(model_lat))
qqnorm(residuals(model_lat))
qqline(residuals(model_lat))
shapiro.test(residuals(model_lat))
model_lat_int <- lm(lat ~ temp*gs,data)
summary(model_lat_int)
plot(fitted(model_lat_int), residuals(model_lat_int))
qqnorm(residuals(model_lat_int))
qqline(residuals(model_lat_int))
shapiro.test(residuals(model_lat_int))
require(MASS)
boxcox(model_lat, lambda = seq(-10, 0, 1/10),plotit=TRUE)
model_quad <- lm(lat ~ temp + gs + I(temp^2),data)
summary(model_quad)
plot(fitted(model_quad), residuals(model_quad))
qqnorm(residuals(model_quad))
qqline(residuals(model_quad))
shapiro.test(residuals(model_quad))
model_quad_int <- lm(lat ~ temp*gs + I(temp^2),data)
summary(model_quad_int)
plot(fitted(model_quad_int), residuals(model_quad_int))
qqnorm(residuals(model_quad_int))
qqline(residuals(model_quad_int))
shapiro.test(residuals(model_quad_int))
model_pois <- glm(lat ~ temp + gs, family = poisson,stats_speed_acc_latency)
summary(model_pois)
model_glm <- glm.nb(lat ~ gs*temp, data)
summary(model_glm)
model_pois_quad <- glm(lat ~ temp + gs + I(temp^2), family = poisson,stats_speed_acc_latency)
summary(model_pois_quad)
model_quad_int <- lm(lat ~ temp*gs + I(temp^2),data)
summary(model_quad_int)
library(readr)
stats_loom_latency_nan <- read_csv("Documents/data/temp_collective/roi/stats_loom_latency_nan.csv")
View(stats_loom_latency_nan)
setwd("~/Documents/code/stats")
data <- read.csv("../../data/temp_collective/roi/stats_loom_latency_nan.csv",header=TRUE,na.strings=c("[nan]"))
lat1 <- data$latency
temp <- stats_loom_latency$Temperature
gs <- stats_loom_latency$Groupsize
loom <- stats_loom_latency$loom
n <- length(lat1)
lat <- data$latency
model1 <- lm(lat ~ temp + gs,data)
summary(model1)
temp <- data$Temperature
gs <- data$Groupsize
loom <- data$loom
n <- length(lat1)
model1 <- lm(lat ~ temp + gs,data)
summary(model1)
library(readr)
stats_loom_latency_nan <- read_csv("~/Documents/data/temp_collective/roi/stats_loom_latency_nan.csv")
View(stats_loom_latency_nan)
setwd("~/Documents/code/stats")
data <- read.csv("../../data/temp_collective/roi/stats_loom_latency_nan.csv",header=TRUE,na.strings=c("[nan]"))
lat <- data$latency
temp <- data$Temperature
gs <- data$Groupsize
loom <- data$loom
n <- length(lat)
model1 <- lm(lat ~ temp + gs,data)
summary(model1)
model2 <- lm(lat ~ temp*gs,data)
summary(model1)
summary(model2)
model3 <- lm(lat ~ temp + gs + loom,data)
summary(model3)
model4 <- lm(lat ~ temp*gs + loom,data)
summary(model4)
model5 <- lm(lat ~ temp+gs + loom+I(temp^2),data)
summary(model5)
model6 <- lm(lat ~ temp*gs + loom+I(temp^2),data)
summary(model6)
model7 <- lm(lat ~ temp*loom + gs +I(temp^2),data)
summary(model7)
model8 <- lm(lat ~ temp*loom*gs +I(temp^2),data)
summary(model8)
model8 <- lm(lat ~ loom*gs + temp + I(temp^2),data)
summary(model8)
summary(model8)
plot(fitted(model8), residuals(model8))
qqnorm(residuals(model8))
qqline(residuals(model8))
model9 <- lm(lat ~ temp*loom*gs +I(temp^2),data)
summary(model9)
plot(fitted(model9), residuals(model9))
qqnorm(residuals(model9))
qqline(residuals(model9))
model10 <- lm(lat ~ temp*loom*gs*I(temp^2),data)
summary(model10)
plot(fitted(model10), residuals(model10))
qqnorm(residuals(model10))
qqline(residuals(model10))
lat
library(readr)
startles_ratio_csv <- read_csv("~/Documents/data/temp_collective/roi/startles_ratio_csv.csv")
View(startles_ratio_csv)
data <- read.csv("../../data/temp_collective/roi/startles_ration_csv.csv",header=TRUE,na.strings=c("[nan]"))
=======
model_acc <- lm(acc ~ temp + gs,data)
summary(model_acc)
plot(fitted(model_acc), residuals(model_acc))
qqnorm(residuals(model_acc))
qqline(residuals(model_acc))
model_acc_int <- lm(acc ~ temp*gs,data)
summary(model_acc_int)
plot(fitted(model_acc_int), residuals(model_acc_int))
qqnorm(residuals(model_acc_int))
qqline(residuals(model_acc_int))
require(MASS)
boxcox(model_acc,plotit=TRUE)
model_inv <- lm(log(acc) ~ temp + gs,speed_data)
summary(model_inv)
plot(fitted(model_inv), residuals(model_inv))
qqnorm(residuals(model_inv))
qqline(residuals(model_inv))
model_exp_inv <- lm(log(speed) ~ temp*gs,speed_data)
summary(model_exp_inv)
plot(fitted(model_exp_inv), residuals(model_exp_inv))
model_exp <- lm(log(speed) ~ temp + gs,speed_data)
summary(model_exp)
plot(fitted(model_exp), residuals(model_exp))
model_exp <- lm(log(speed) ~ temp + as.factor(gs),speed_data)
summary(model_exp)
model_exp <- lm(log(speed) ~ temp + gs,speed_data)
summary(model_exp)
model_exp <- lm(log(speed) ~ temp + log(gs),speed_data)
summary(model_exp)
model_exp <- lm(log(speed) ~ temp + log(gs,2),speed_data)
summary(model_exp)
data <- read.csv("../../data/temp_collective/roi/stats_loom_latency_nan.csv",header=TRUE,na.strings=c("[nan]"))
lat <- data$latency
hist(lat)
temp <- data$Temperature
gs <- data$Groupsize
loom <- data$loom
model8 <- lm(lat ~ loom*gs + temp + I(temp^2),data)
summary(model8)
plot(fitted(model8), residuals(model8))
qqnorm(residuals(model8))
qqline(residuals(model8))
model_pois3 <- glm.nb(lat ~ temp*gs, data)
summary(model_pois3)
model_pois2 <- glm(lat ~ temp*gs, family = quasipoisson, data)
summary(model_pois2)
model_pois <- glm(lat ~ temp + gs, family = quasipoisson, data)
summary(model_pois)
>>>>>>> 2d075bd6684d6849204457f05e6bb5e0a9ad2f87
data <- read.csv("../../data/temp_collective/roi/startles_ratio_csv.csv",header=TRUE,na.strings=c("[nan]"))
accuracy <- data$accuracy
temp <- data$Temperature
gs <- data$Groupsize
<<<<<<< HEAD
date <- data$Date
date
time_in <- data$Time_fish_in
time_record <- data$Time_start_record
time_in[1]
time_in[0]
time_record[1]
time_record[1] - time_in[1]
as.Date(time_in[1], format = "%m/%d/%Y")
as.POSIXct("25072013 08:32:07", format = "%d%m%Y %H:%M:%S")
as.POSIXct(time_in[1], format = "%H:%M")
as.POSIXct(time_record[1], format = "%H:%M") - as.POSIXct(time_in[1], format = "%H:%M")
a = as.POSIXct(time_record[1], format = "%H:%M") - as.POSIXct(time_in[1], format = "%H:%M")
a
date[1]
as.Date(date[1], format = "%m/%d/%Y")
as.Date(date[1], format = "%d/%m/%Y")
date <- as.Date(data$Date, format = "%d/%m/%Y")
time_in <- as.POSIXct(data$Time_fish_in, format = "%H:%M")
time_record <- as.POSIXct(data$Time_start_record, format = "%H:%M")
date[1] - date[2]
date[1]
as.numeric(date[1])
date[3]
as.numeric(date[3])
date <- as.numeric(as.Date(data$Date, format = "%d/%m/%Y"))
date
time_in[1]
as.numeric(time_in[1])
as.numeric(time_record[1])
as.numeric(time_record[1]) - as.numeric(time_in[1])
as.numeric(time_record[2]) - as.numeric(time_in[2])
as.numeric(time_record[10]) - as.numeric(time_in[10])
time_in <- as.numeric(as.POSIXct(data$Time_fish_in, format = "%H:%M"))
time_record <- as.numeric(as.POSIXct(data$Time_start_record, format = "%H:%M"))
difference <- time_record - time_in
difference
library(reticulate)
np <- import("numpy")
install.packages("reticulate")
library(reticulate)
np <- import("numpy")
n
mat <- np$load("fmat.npy")
getwd()
setwd("~/Documents/data/temp_collective/roi/13/1/GS_1_T_13_roi_1")
mat <- np$load("trajectories.npy")
mat <- np$load("trajectories.npy",allow_pickle = True)
mat <- np$load("trajectories.npy",allow_pickle = TRUE)
mat
mat[1]
mat.shape
mat[1][1]
View(mat)
mat[[1]][["trajectories"]]
mat[[1]][["trajectories"]][1]
mat[[1]][["trajectories"]][1][1]
mat[[1]][["trajectories"]][1][2]
mat[[1]][["trajectories"]][0]
mat[[1]][["trajectories"]][2]
mat[[1]][["trajectories"]][9544]
shape()
length(mat[[1]][["trajectories"]])
97119*2
mat[[1]][["trajectories"]][194238]
model1 <- lm(accuracy ~ temp + gs,data)
summary(model1)
model2 <- lm(accuracy ~ temp + gs + I(temp^2),data)
summary(model2)
plot(fitted(model1), residuals(model1))
qqnorm(residuals(model1))
qqline(residuals(model1))
require(MASS)
boxcox(model1,plotit=TRUE)
accuracy
model3 <- lm(accuracy ~ temp + gs + date + difference,data)
summary(model3)
plot(fitted(model3), residuals(model3))
qqnorm(residuals(model3))
qqline(residuals(model3))
plot(fitted(model3)^2, residuals(model3))
plot(fitted(model3), residuals(model3)^2)
library(readr)
startles_ratio_zero <- read_csv("~/Documents/data/temp_collective/roi/startles_ratio_zero.csv")
View(startles_ratio_zero)
data1 <- read.csv("../../data/temp_collective/roi/startles_ratio_zero.csv",header=TRUE,na.strings=c("[nan]"))
accuracy1 <- data1$accuracy
temp1 <- data1$Temperature
gs1 <- data1$Groupsize
date1 <- as.numeric(as.Date(data1$Date, format = "%d/%m/%Y"))
time_in1 <- as.numeric(as.POSIXct(data1$Time_fish_in, format = "%H:%M"))
time_record1 <- as.numeric(as.POSIXct(data1$Time_start_record, format = "%H:%M"))
difference1 <- time_record - time_in
setwd("~/Documents/data/temp_collective/roi")
library(readr)
startles_ratio_zero <- read_csv("~/Documents/data/temp_collective/roi/startles_ratio_zero.csv")
View(startles_ratio_zero)
data1 <- read.csv("../../data/temp_collective/roi/startles_ratio_zero.csv",header=TRUE,na.strings=c("[nan]"))
accuracy1 <- data1$accuracy
temp1 <- data1$Temperature
gs1 <- data1$Groupsize
date1 <- as.numeric(as.Date(data1$Date, format = "%d/%m/%Y"))
time_in1 <- as.numeric(as.POSIXct(data1$Time_fish_in, format = "%H:%M"))
time_record1 <- as.numeric(as.POSIXct(data1$Time_start_record, format = "%H:%M"))
difference1 <- time_record - time_in
setwd("~/Documents/code/stats")
data1 <- read.csv("../../data/temp_collective/roi/startles_ratio_zero.csv",header=TRUE,na.strings=c("[nan]"))
accuracy1 <- data1$accuracy
temp1 <- data1$Temperature
gs1 <- data1$Groupsize
date1 <- as.numeric(as.Date(data1$Date, format = "%d/%m/%Y"))
time_in1 <- as.numeric(as.POSIXct(data1$Time_fish_in, format = "%H:%M"))
time_record1 <- as.numeric(as.POSIXct(data1$Time_start_record, format = "%H:%M"))
difference1 <- time_record - time_in
model4 <- lm(accuracy1 ~ temp1 + gs1,data1)
summary(model4)
plot(fitted(model4), residuals(model4))
qqnorm(residuals(model4))
qqline(residuals(model4))
require(MASS)
boxcox(model4,plotit=TRUE)
model5 <- lm(accuracy1^(3/2) ~ temp1 + gs1,data1)
summary(model5)
plot(fitted(model5), residuals(model5))
qqnorm(residuals(model5))
qqline(residuals(model5))
model6 <- lm(accuracy^(3/2) ~ temp + gs,data)
summary(model6)
plot(fitted(model6), residuals(model6))
qqnorm(residuals(model6))
qqline(residuals(model6))
model5 <- lm(I(accuracy1^(3/2)) ~ temp1 + gs1,data1)
summary(model5)
model7 <- lm(accuracy ~ temp*gs,data)
summary(model7)
plot(fitted(model7), residuals(model7))
qqnorm(residuals(model7))
qqline(residuals(model7))
model8 <- lm(accuracy1 ~ temp1*gs1,data1)
summary(model8)
plot(fitted(model8), residuals(model8))
qqnorm(residuals(model8))
qqline(residuals(model8))
require(MASS)
boxcox(model8,plotit=TRUE)
model9 <- lm(accuracy1^(3/2) ~ temp1*gs1,data1)
summary(model9)
plot(fitted(model9), residuals(model9))
qqnorm(residuals(model9))
qqline(residuals(model9))
mat[[1]][["trajectories"]]
mat[[1]][["trajectories"]][0]
mat[[1]][["trajectories"]][9544]
mat[[1]][["trajectories"]][10]
mat[[1]][["trajectories"]][1]
mat[[1]][["trajectories"]][1][1]
mat[[1]][["trajectories"]][1][2]
mat[[1]][["trajectories"]][1][2]
mat[[1]][["trajectories"]][1][23
]
mat[[1]][["trajectories"]][9544,1]
mat[[0]][["trajectories"]][9544,1]
mat[[2]][["trajectories"]][9544]
library(readr)
GS_1_T_13_rep_1 <- read_csv("~/Documents/data/temp_collective/csv/GS_1_T_13_rep_1.csv")
View(GS_1_T_13_rep_1)
data_csv <- read.csv(GS_1_T_13_rep_1)
data_csv <- read.csv("../../data/temp_collective/csv/GS_1_T_13_rep_1.csv")
data_csv$acceleration
=======
date <- as.numeric(as.Date(data$Date, format = "%d/%m/%Y"))
time_in <- as.numeric(as.POSIXct(data$Time_fish_in, format = "%H:%M"))
time_record <- as.numeric(as.POSIXct(data$Time_start_record, format = "%H:%M"))
difference <- time_record - time_in
View(data)
hist(accuracy)
model10 <- glm(accuracy ~ temp + gs, family = binomial,data)
summary(model10)
model11 <- glm(accuracy ~ temp*gs, family = binomial,data)
summary(model11)
model12 <- glm(accuracy ~ temp*gs + I(temp^2), family = binomial,data)
summary(model12)
model13 <- glm(accuracy ~ temp*gs + I(temp^2)*gs, family = binomial,data)
summary(model12)
setwd("~/Documents/code/stats")
data <- read.csv("../../data/temp_collective/roi/stats_loom_latency_nan.csv",header=TRUE,na.strings=c("[nan]"))
lat <- data$latency
#lat <- as.numeric(lat1)
temp <- data$Temperature
gs <- data$Groupsize
loom <- data$loom
model_pois <- glm(lat ~ temp + gs, family = quasipoisson, data)
summary(model_pois)
model_pois2 <- glm(lat ~ temp*gs, family = quasipoisson, data)
summary(model_pois2)
>>>>>>> 2d075bd6684d6849204457f05e6bb5e0a9ad2f87
